---
title: "Extended models for lab accidents"
author: "Joshua Blake"
date: "`r Sys.Date()`"
---

Work-in-progress sigmoid models.
Use at your own risk.

```{r setup, include=FALSE}
library(broom)
library(dplyr)
library(ggplot2)
library(purrr)
library(tidyr)
knitr::opts_chunk$set(fig.width = 10)

incident_counts = readr::read_csv(here::here("data/lab-accidents.csv"), show_col_types = FALSE) |>
    filter(!is.na(Year))  |> # Extra rows added when copying from web
    mutate(
        year = case_match(
            Year,
            "Late 1970s" ~ 1977,
            .default = suppressWarnings(as.integer(stringr::str_sub(Year, end = 4)))
        )
    ) |>
    assertr::assert(assertr::not_na, year) |>
    count(year) |>
    complete(
        year = 1975:2016,
        fill = list(n = 0)
    ) |>
    mutate(type = "Lab accidents")

lab_counts = readr::read_csv(here::here("data/bsl4.csv"), show_col_types = FALSE) |>
    group_by(year = floor(year)) |>
    summarise(labs = floor(min(labs))) |>
    transmute(
        year,
        `New BSL4 labs` = labs - lag(labs),
    ) |>
    pivot_longer(-year, names_to = "type", values_to = "n") |>
    filter(!is.na(n))
web_of_science_counts = readr::read_tsv(here::here("data/web-of-science.tsv")) |>
    rename(year = `Publication Years`, n = `Record Count`) |>
    complete(
        year = 1953:2022,
        fill = list(n = 0)
    ) |>
    select(year, n) |>
    filter(year <= 2022) |>
    mutate(type = "Web of Science articles")

all_counts = bind_rows(
    incident_counts,
    lab_counts,
    web_of_science_counts,
)
```


# Breakpoint analysis

The plots above suggest the rate of growth is changing.
Here, I allow two breakpoints in the rate.
A more parsimonious model would be a sigmoid, but I failed to fit one to the data...

```{r}
library(segmented)
all_counts |>
    ggplot(aes(year, n)) +
    geom_point() +
    facet_wrap(~type, scales = "free_y")
break_fit = segmented(
    obj = MASS::glm.nb(
        n ~ year + type,
        data = all_counts
    ),
    seg.Z = ~year,
    psi = c(1990, 2010)
)
summary(break_fit)
augment(break_fit, newdata = all_counts, type.predict = "response") |>
    ggplot(aes(year, .fitted)) +
    geom_line() +
    geom_point(aes(year, n)) +
    geom_ribbon(
        aes(
            ymin = qnbinom(0.025, mu = .fitted, size = break_fit$theta),
            ymax = qnbinom(0.975, mu = .fitted, size = break_fit$theta),
        ),
        alpha = 0.3,
    ) +
    theme_minimal() +
    facet_wrap(~type, scales = "free_y") +
    labs(
        x = "Year",
        y = "Count"
    )
```

# Bayesian

## Exponential

```{r}
library(brms)
exp_fit = brm(
    n ~ I(year-2000) + type + (I(year-2000) - 1 | type) - 1,
    data = fit_counts,
    family = "poisson",
    cores = 4,
    prior = prior(normal(0, 0.1), coef = "IyearM2000") +
        prior(exponential(100), class = "sd"),
    init = 0
)
summary(exp_fit)
library(tidybayes)
all_counts |>
    add_predicted_draws(exp_fit) |>
    median_qi() |>
    ggplot(aes(year, .prediction, ymin = .lower, ymax = .upper)) +
    geom_lineribbon(alpha = 0.3) +
    geom_point(aes(y = n)) +
    facet_wrap(~type, scales = "free_y") +
    theme_minimal()
```

## Sigmoid

```{r}
sig_fit_wos = brm(
    bf(
        n ~ exp(a) * inv_logit(b * ((year - 1950) - c)),
        a + b + c ~ 1,
        # max ~ type - 1,
        nl = TRUE
    ),
    data = filter(all_counts, type == "Web of Science articles"),
    prior = prior(normal(0, 0.1), nlpar = "b") +
        prior(exponential(0.01), nlpar = "c", lb = 0) + 
        prior(normal(0, 10), nlpar = "a"),
    family = poisson("identity"),
    cores = 4,
    init = function() list(
        a = log(9000),
        b = 0.05,
        c = 30
    )
)
summary(sig_fit_wos)
all_counts |>
    add_predicted_draws(sig_fit_wos) |>
    median_qi() |>
    ggplot(aes(year, .prediction, ymin = .lower, ymax = .upper)) +
    geom_lineribbon(alpha = 0.3) +
    geom_point(aes(y = n)) +
    facet_wrap(~type, scales = "free_y") +
    theme_minimal()
```


```{r}
sig_fit = brm(
    bf(
        n ~ exp(a) * inv_logit(b * ((year - 1950) - c)),
        b + c ~ 1,
        a ~ type - 1,
        nl = TRUE
    ),
    data = all_counts,
    prior = prior(normal(0, 0.1), nlpar = "b") +
        prior(exponential(0.01), nlpar = "c", lb = 0) + 
        prior(normal(0, 10), nlpar = "a"),
    family = poisson("identity"),
    cores = 4,
    init = function() list(
        a = log(9000),
        b = 0.05,
        c = 30
    )
)
summary(sig_fit)
all_counts |>
    add_predicted_draws(sig_fit) |>
    median_qi() |>
    ggplot(aes(year, .prediction, ymin = .lower, ymax = .upper)) +
    geom_lineribbon(alpha = 0.3) +
    geom_point(aes(y = n)) +
    facet_wrap(~type, scales = "free_y") +
    theme_minimal()
```

Yay, a working fit!
However, the latest flattening looks suspiciously like the one in the 1990s.
Lets add overdispersion.
    
```{r}
sig_fit_nb = brm(
    bf(
        n ~ exp(a) * inv_logit(b * ((year - 1950) - c)),
        b + c ~ 1,
        a ~ type - 1,
        nl = TRUE
    ),
    data = all_counts,
    prior = prior(normal(0, 0.1), nlpar = "b") +
        prior(exponential(0.01), nlpar = "c", lb = 0) + 
        prior(normal(0, 10), nlpar = "a"),
    family = negbinomial("identity"),
    cores = 4,
    init = function() list(
        a = log(9000),
        b = 0.05,
        c = 30
    )
)
summary(sig_fit_nb)
all_counts |>
    add_predicted_draws(sig_fit_nb) |>
    median_qi() |>
    ggplot(aes(year, .prediction, ymin = .lower, ymax = .upper)) +
    geom_lineribbon(alpha = 0.3) +
    geom_point(aes(y = n)) +
    facet_wrap(~type, scales = "free_y") +
    theme_minimal()
```

Now I look at the virology plot more closely, it does look a lot like a couple of steps (one in late 1980s and one around 2005) with plateuing in between.