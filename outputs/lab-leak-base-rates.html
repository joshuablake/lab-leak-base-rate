<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Joshua Blake" />

<meta name="date" content="2023-12-27" />

<title>Code and maths for lab accidents causing pandemics</title>

<script src="libs/header-attrs-2.23/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>
<script src="libs/navigation-1.1/codefolding.js"></script>
<link href="libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>




</head>

<body>


<div class="container-fluid main-container">




<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Code and maths for lab accidents causing pandemics</h1>
<h4 class="author">Joshua Blake</h4>
<h4 class="date">2023-12-27</h4>

</div>


<pre class="r"><code>library(broom)
library(dplyr)
library(ggplot2)
library(purrr)
library(tidyr)
knitr::opts_chunk$set(fig.width = 10)</code></pre>
<div id="summary" class="section level1">
<h1>Summary</h1>
<ul>
<li>I aim to estimate the base rate of lab accidents causing pandemics. By lab accidents, I mean any pandemic that was not intentional but would not have occurred without human intervention in a research setting. That could include virus hunting, gain-of-function research, or other experiments. Pandemics are defined as killing at least 1 in 100,000 of the global population, around 80,000 deaths (this is the threshold from Marani et al. 2021).</li>
<li>I use three proxies for the amount of risky research being conducted: the number of BSL-4 labs, the number of lab accidents, and the number of virology papers published. Note that I am not attempting to quantify the actual number of lab-years contributing. These have all been growing at the same exponential rate over the past few decades, meaning that they agree on the amount of risk.</li>
<li>There have been 1 lab-leak pandemics to date: the 1977 Russian flu pandemic. COVID-19’s origin is debated, and I present either scenario. I make no attempt or provide judgment on COVID-19’s origin.</li>
<li>I estimate that we should expect 1 or 2 pandemics in the next decade, with around a 60% chance that at least 1 occurs. For context, the historical record suggests, in expectation, 2.5 zoonotic pandemics over the next decade.</li>
<li>I am 80% confident that this is an overestimate for the following reasons.
<ul>
<li>The Russian flu pandemic was caused by labs with much less safety than modern ones.</li>
<li>COVID-19, if it were a lab-leak, was downstream of the PREDICT virus hunting effort. The only comparable successor programme, DEEP VZN, has been canceled.</li>
<li>The number of virology papers being published has been declining since the second half of the 2000s, which is not included in my extrapolation of growth rates. This could indicate that less risky research is being conducted than my extrapolation suggests.</li>
</ul></li>
<li>The main reason to think this is an underestimate is that technological advances could accelerate the rate of risky research. For example, if experimentation with viruses that could infect humans was being performed by biohackers outside of formal laboratories. This could lead to a discontinuous increase in the rate of risky research, or an increase that is not captured well by the proxies I have used.</li>
</ul>
</div>
<div id="methods" class="section level1">
<h1>Methods</h1>
<p>To estimate the base rate, we need two quantities. First, the number of pandemics that lab accidents have caused. This can be easily found by looking at the historic record. Second, a measure of the amount of lab experiments that could cause such a pandemic; I refer to this as “risky research units”. I then extrapolate research units into the future to forecast a base rate for lab accidents causing pandemics.</p>
<p>No good data exists on risky research units directly. However, by applying a continuous time <a href="https://joshuablake.co.uk/blog/gamma-poisson/">Gamma-Poisson model</a> we only need a measure that is proportional to the number of experiments.</p>
</div>
<div id="measuring-risky-research-units" class="section level1">
<h1>Measuring risky research units</h1>
<p>I consider three proxies for the number of risky research units being conducted. First, the number of BSL-4 labs (<a href="https://static1.squarespace.com/static/62fa334a3a6fe8320f5dcf7e/t/6412d3120ee69a4f4efbec1f/1678955285754/KCL0680_BioLabs+Report_Digital.pdf">GlobalBioLabs 2023</a>). I transform this into the net increase in labs per year to reduce autocorrelation. Second, the number of known lab accidents as reported by <a href="https://f1000research.com/articles/10-752">Manheim and Lewis 2022</a>. Third, the number of virology papers published per year according to Web of Science (downloaded from their website). These appear to be growing at roughly the same rate, as seen by fitting either separate or joint Poisson regressions to the datasets.</p>
<pre class="r"><code>incident_counts = readr::read_csv(here::here(&quot;data/lab-accidents.csv&quot;), show_col_types = FALSE) |&gt;
    filter(!is.na(Year))  |&gt; # Extra rows added when copying from web
    mutate(
        year = case_match(
            Year,
            &quot;Late 1970s&quot; ~ 1977,
            .default = suppressWarnings(as.integer(stringr::str_sub(Year, end = 4)))
        )
    ) |&gt;
    assertr::assert(assertr::not_na, year) |&gt;
    count(year) |&gt;
    complete(
        year = 1975:2016,
        fill = list(n = 0)
    ) |&gt;
    mutate(type = &quot;Lab accidents&quot;)

lab_counts = readr::read_csv(here::here(&quot;data/bsl4.csv&quot;), show_col_types = FALSE) |&gt;
    group_by(year = floor(year)) |&gt;
    summarise(labs = floor(min(labs))) |&gt;
    transmute(
        year,
        `New BSL4 labs` = labs - lag(labs),
    ) |&gt;
    pivot_longer(-year, names_to = &quot;type&quot;, values_to = &quot;n&quot;) |&gt;
    filter(!is.na(n))
web_of_science_counts = readr::read_tsv(here::here(&quot;data/web-of-science.tsv&quot;)) |&gt;
    rename(year = `Publication Years`, n = `Record Count`) |&gt;
    complete(
        year = 1953:2022,
        fill = list(n = 0)
    ) |&gt;
    select(year, n) |&gt;
    filter(year &lt;= 2022) |&gt;
    mutate(type = &quot;Web of Science articles&quot;)</code></pre>
<pre><code>## Rows: 71 Columns: 3
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## Delimiter: &quot;\t&quot;
## dbl (3): Publication Years, Record Count, % of 277,012
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<pre class="r"><code>all_counts = bind_rows(
    incident_counts,
    lab_counts,
    web_of_science_counts,
)

fit_counts = bind_rows(
    incident_counts,
    lab_counts,
    web_of_science_counts |&gt; filter(year &lt;= 2010),
)

tbl_models = fit_counts |&gt;
    nest(data = !type) |&gt;
    mutate(
        fit = map(data, ~glm(n ~ year, data = .x, family = &quot;poisson&quot;)),
    ) |&gt;
    add_row(
        type = &quot;Joint&quot;,
        fit = list(glm(n ~ year + type, data = fit_counts, family = &quot;poisson&quot;)),
    ) |&gt;
    mutate(
        fit_aug = map(fit, broom::augment, se_fit = TRUE),
        fit_tidy = map(fit, broom::tidy, conf.int = TRUE),
    ) |&gt;
    rename(model_type = type)
final_growth_rate = tbl_models |&gt;
    unnest(fit_tidy) |&gt;
    filter(term == &quot;year&quot;, model_type == &quot;Joint&quot;) |&gt;
    assertr::verify(length(estimate) == 1) |&gt;
    pull(estimate)</code></pre>
<pre class="r"><code>tbl_models |&gt;
    unnest(fit_aug) |&gt;
    mutate(
        type = if_else(is.na(type), model_type, type),
        .fitted.n = exp(.fitted),
        ymin = qpois(0.025, exp(.fitted)),
        ymax = qpois(0.975, exp(.fitted)),
    ) |&gt;
    # mutate(across(c(ymin, ymax, n, .fitted.n), ~.x / max(n)), .by = type) |&gt;
    ggplot(aes(year, .fitted.n)) +
    geom_line(aes(color = model_type)) +
    geom_ribbon(
        aes(year, ymin = ymin, ymax = ymax, fill = model_type),
        alpha = 0.3,
    ) +
    geom_point(aes(year, n), data = all_counts) +
    facet_wrap(~type, scales = &quot;free_y&quot;) +
    theme_minimal()</code></pre>
<div class="figure">
<img src="lab-leak-base-rates_files/figure-html/unnamed-chunk-2-1.png" alt="Poisson regression from fitting to each time series either individually or jointly (jointly assumes the same growth rate)." width="960" />
<p class="caption">
Poisson regression from fitting to each time series either individually or jointly (jointly assumes the same growth rate).
</p>
</div>
<pre class="r"><code>tbl_models |&gt;
    filter(model_type == &quot;Joint&quot;) |&gt;
    unnest(fit_aug) |&gt;
    mutate(
        .fitted.n = exp(.fitted),
        ymin = qpois(0.025, exp(.fitted)),
        ymax = qpois(0.975, exp(.fitted)),
    ) |&gt;
    # mutate(across(c(ymin, ymax, n, .fitted.n), ~.x / max(n)), .by = type) |&gt;
    ggplot(aes(year, .fitted.n)) +
    geom_line() +
    geom_ribbon(
        aes(year, ymin = ymin, ymax = ymax),
        alpha = 0.3,
    ) +
    geom_point(aes(year, n), data = all_counts) +
    facet_wrap(~type, scales = &quot;free_y&quot;) +
    theme_minimal() +
    labs(
        x = &quot;Year&quot;,
        y = &quot;Number of events&quot;
    )
    ggsave(
        here::here(&quot;outputs/poisson-regression.png&quot;),
        width = 15,
        height = 10,
        units = &quot;cm&quot;,
        dpi = 200
    )</code></pre>
<pre class="r"><code>fit_wos = glm(n ~ year, data = filter(web_of_science_counts, year &lt;= 2010), family = &quot;poisson&quot;)
augment(fit_wos, type.predict = &quot;response&quot;, newdata = web_of_science_counts) |&gt;
    ggplot(aes(year, .fitted)) +
    geom_line() +
    geom_point(aes(year, n)) +
    geom_ribbon(
        aes(year, ymin = qpois(0.025, .fitted), ymax = qpois(0.975, .fitted)),
        alpha = 0.3,
    ) +
    theme_minimal() +
    labs(
        x = &quot;Year&quot;,
        y = &quot;Number of papers published&quot;
    )</code></pre>
<pre class="r"><code>tbl_models |&gt;
    unnest(fit_tidy) |&gt;
    filter(term == &quot;year&quot;) |&gt;
    ggplot(aes(estimate, model_type, xmin = estimate - 1.96 * std.error, xmax = estimate + 1.96 * std.error)) +
    geom_pointrange() +
    theme_minimal() +
    labs(
        x = &quot;Growth rate&quot;,
        y = &quot;Model&quot;
    )</code></pre>
<div class="figure">
<img src="lab-leak-base-rates_files/figure-html/unnamed-chunk-5-1.png" alt="Growth rates from fitting to each time series either individually or jointly." width="960" />
<p class="caption">
Growth rates from fitting to each time series either individually or jointly.
</p>
</div>
</div>
<div id="forecast" class="section level1">
<h1>Forecast</h1>
<p>One lab risk pandemic has occurred to date: the 1977 Russian flu pandemic. COVID-19’s origin is debated, and I present either scenario.</p>
<p>The forecast will be based on three quantities. These can be calculated from the historic record, and the growth rate of risky research units <span class="math inline">\(r\)</span> estimated above.</p>
<ul>
<li>The number of risky research units conducted up until the time used for calculating the base rate, <span class="math inline">\(t_b\)</span>. We will normalize this to 1, meaning that we define the number of units as <span class="math inline">\(u(t) = r \exp(r(t-t_b))\)</span>. This gives the total risky research units conducted up until <span class="math inline">\(t_b\)</span> as <span class="math inline">\(\int_{-\infty}^{t_b} u(t) dt = \exp(0) - \exp(-\infty) = 1\)</span>.</li>
<li>The number of risky research units conducted in the period we are predicting, from <span class="math inline">\(t_0\)</span> for <span class="math inline">\(d\)</span> years. This is <span class="math inline">\(u_p = \int_{t_0}^{t_0+d} u(t) dt = \exp(r(t_0+d-t_b)) - \exp(r(t_0-t_b)) = \exp(r(t_0-t_b)) (\exp(rd) - 1)\)</span>.</li>
<li>The number of lab-leak pandemics that have occurred in the period used for calculating the base rate.</li>
</ul>
<p>The estimate for the expected number of lab-leak pandemics per risky research unit (using a Gamma(1/3, 1/3) prior) is Gamma(a+1/3, 1). The expected number of lab-leak pandemics over the period of interest is <span class="math inline">\(u_p(a + 1/3)\)</span>. The probability of there being at least one pandemic is <span class="math inline">\(1 - 1 / (1 + u_p)^(a + 1/3)\)</span>.</p>
<p>This gives the following results, with r = 0.0584812</p>
<pre class="r"><code>r = final_growth_rate
leak_risks = tribble(
    ~Scenario, ~a, ~tb, 
    &quot;No pandemics&quot;, 0, 2023,
    &quot;Pre-COVID&quot;, 1, 2019,
    &quot;COVID zoonotic&quot;, 1, 2023,
    &quot;COVID lab-leak&quot;, 2, 2023,
) |&gt;
    mutate(
        t0 = 2024,
        d = 10,
        up = exp(r * (t0 - tb)) * (expm1(r * d)),
        E_lab_leaks = up * (a + 1/3),
        p_gte1_lab_leaks = 1 - 1 / (1 + up) ^ (a + 1/3),
    )
leak_risks</code></pre>
<pre><code>## # A tibble: 4 × 8
##   Scenario           a    tb    t0     d    up E_lab_leaks p_gte1_lab_leaks
##   &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;            &lt;dbl&gt;
## 1 No pandemics       0  2023  2024    10 0.843       0.281            0.184
## 2 Pre-COVID          1  2019  2024    10 1.06        1.42             0.620
## 3 COVID zoonotic     1  2023  2024    10 0.843       1.12             0.557
## 4 COVID lab-leak     2  2023  2024    10 0.843       1.97             0.760</code></pre>
<p>Full probability distributions</p>
<pre class="r"><code>prob_dist = leak_risks |&gt;
    cross_join(tibble(n = 0:10)) |&gt;
    mutate(p = dnbinom(n, a + 1/3, 1 / (up + 1))) |&gt;
    pivot_wider(
        names_from = Scenario,
        id_cols = n,
        values_from = p,
    )
prob_dist</code></pre>
<pre><code>## # A tibble: 11 × 5
##        n `No pandemics` `Pre-COVID` `COVID zoonotic` `COVID lab-leak`
##    &lt;int&gt;          &lt;dbl&gt;       &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;
##  1     0      0.816         0.380           0.443             0.240  
##  2     1      0.124         0.262           0.270             0.256  
##  3     2      0.0379        0.157           0.144             0.195  
##  4     3      0.0135        0.0901          0.0732            0.129  
##  5     4      0.00514       0.0504          0.0362            0.0787 
##  6     5      0.00204       0.0277          0.0177            0.0456 
##  7     6      0.000827      0.0151          0.00853           0.0255 
##  8     7      0.000342      0.00814         0.00409           0.0139 
##  9     8      0.000143      0.00437         0.00195           0.00740
## 10     9      0.0000607     0.00234         0.000923          0.00388
## 11    10      0.0000259     0.00125         0.000436          0.00201</code></pre>
<p>Cumulative distribution</p>
<pre class="r"><code>prob_dist |&gt;
    mutate(across(-n, cumsum))</code></pre>
<pre><code>## # A tibble: 11 × 5
##        n `No pandemics` `Pre-COVID` `COVID zoonotic` `COVID lab-leak`
##    &lt;int&gt;          &lt;dbl&gt;       &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;
##  1     0          0.816       0.380            0.443            0.240
##  2     1          0.940       0.642            0.713            0.497
##  3     2          0.978       0.799            0.857            0.692
##  4     3          0.991       0.889            0.930            0.821
##  5     4          0.997       0.940            0.966            0.900
##  6     5          0.999       0.967            0.984            0.945
##  7     6          0.999       0.982            0.992            0.971
##  8     7          1.00        0.991            0.996            0.985
##  9     8          1.00        0.995            0.998            0.992
## 10     9          1.00        0.997            0.999            0.996
## 11    10          1.00        0.999            1.00             0.998</code></pre>
<p>For comparison, Marani et al. (2021) suggests 2.5 zoonotic pandemics per decade, although this rate may have decreased since World War II.</p>
<p>Below I show how the rate is changing over time due to the change in risky research units.</p>
<pre class="r"><code>leak_risks |&gt;
    cross_join(tibble(time = 2010:2050)) |&gt;
    mutate(
        E_lab_leak_pandemics = r * exp(r * (time - tb)) * (a + 1/3),
    ) |&gt;
    ggplot(aes(time, E_lab_leak_pandemics, color = Scenario)) +
    geom_line() +
    geom_hline(aes(colour = &quot;E(zoonotic pandemics)&quot;, yintercept = 0.25)) +
    theme_minimal()</code></pre>
<p><img src="lab-leak-base-rates_files/figure-html/unnamed-chunk-9-1.png" width="960" /></p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
